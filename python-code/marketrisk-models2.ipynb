{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Value at Risk (VaR)\n",
    "Purpose: Estimate the potential loss in value of a portfolio over a defined period for a given confidence interval.\n",
    "Techniques: Historical simulation, Monte Carlo simulation, and parametric methods.\n",
    "Enhancements with ML: Machine learning models can improve the accuracy of VaR calculations by better estimating the distribution of returns, especially in the tails.\n",
    "2. Volatility Forecasting\n",
    "Purpose: Predict future volatility to manage risk, set trading limits, and optimize portfolios.\n",
    "Techniques: GARCH models, Exponential Moving Average (EMA), and machine learning models like LSTM.\n",
    "Enhancements with ML: LSTM and other deep learning models can capture long-term dependencies and complex patterns in volatility data that traditional models might miss.\n",
    "3. Monte Carlo Simulations\n",
    "Purpose: Simulate a wide range of possible future states of the market to assess risk and inform decision-making.\n",
    "Techniques: Random sampling from historical data and applying machine learning to generate realistic market scenarios.\n",
    "Enhancements with ML: Machine learning can be used to enhance scenario generation, providing more accurate and diverse potential outcomes.\n",
    "4. Sentiment Analysis for Market Prediction\n",
    "Purpose: Use market sentiment to predict price movements and volatility, adding an additional layer of information to traditional models.\n",
    "Techniques: Natural Language Processing (NLP) to analyze text data from news articles, social media, and other sources.\n",
    "Enhancements with ML: Sentiment scores derived from NLP can be integrated into predictive models to improve their accuracy.\n",
    "Detailed Examples\n",
    "1. VaR with Historical Simulation Enhanced by Machine Learning\n",
    "Objective: Improve traditional VaR calculations by using machine learning to better model the tail distribution of returns.\n",
    "\n",
    "python\n",
    "Copy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR (95% confidence): -1.6593473865936252\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load historical return data\n",
    "returns = np.random.normal(0, 1, 1000)  # Placeholder for real return data\n",
    "\n",
    "# Machine learning model to predict tail events (e.g., using a regression model)\n",
    "# For simplicity, we use a direct percentile method here\n",
    "VaR_95 = np.percentile(returns, 5)\n",
    "print(f'VaR (95% confidence): {VaR_95}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Volatility Forecasting with GARCH and LSTM Models\n",
    "Objective: Predict future volatility using both traditional GARCH models and machine learning.\n",
    "\n",
    "python\n",
    "Copy code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         h.01     h.02      h.03      h.04      h.05      h.06      h.07  \\\n",
      "999  0.000154  0.00018  0.000192  0.000199  0.000202  0.000204  0.000205   \n",
      "\n",
      "         h.08      h.09      h.10  \n",
      "999  0.000205  0.000205  0.000205  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\arch\\univariate\\base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.0002054. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 100 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from arch import arch_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load historical price data\n",
    "prices = np.random.normal(100, 1, 1000)  # Placeholder for real price data\n",
    "returns = pd.Series(prices).pct_change().dropna()\n",
    "\n",
    "# Fit GARCH model\n",
    "model = arch_model(returns, vol='Garch', p=1, q=1)\n",
    "model_fit = model.fit(disp='off')\n",
    "\n",
    "# Forecast volatility\n",
    "forecast = model_fit.forecast(horizon=10)\n",
    "print(forecast.variance[-1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Monte Carlo Simulations for Scenario Analysis\n",
    "Objective: Use Monte Carlo simulations to generate a range of possible future market scenarios and estimate portfolio risk.\n",
    "\n",
    "python\n",
    "Copy code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR (95% confidence): -0.08583220430910782\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load historical return data\n",
    "returns = np.random.normal(0, 1, 1000)  # Placeholder for real return data\n",
    "\n",
    "# Simulate future returns\n",
    "num_simulations = 10000\n",
    "simulated_returns = np.random.choice(returns, size=(num_simulations, len(returns)), replace=True)\n",
    "portfolio_returns = simulated_returns.mean(axis=1)\n",
    "\n",
    "# Compute VaR at 95% confidence level\n",
    "VaR_95 = np.percentile(portfolio_returns, 5)\n",
    "print(f'VaR (95% confidence): {VaR_95}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Sentiment Analysis for Market Prediction\n",
    "Objective: Use sentiment analysis to enhance market predictions and improve trading strategies.\n",
    "\n",
    "python\n",
    "Copy code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting nltk>=3.8 (from textblob)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting click (from nltk>=3.8->textblob)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.8->textblob)\n",
      "  Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk>=3.8->textblob)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ----------------------------------- ---- 51.2/57.6 kB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 57.6/57.6 kB 751.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 266.2/626.3 kB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 626.3/626.3 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.4/1.5 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.6/1.5 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.4/1.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 268.5/268.5 kB 8.3 MB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, click, nltk, textblob\n",
      "Successfully installed click-8.1.7 nltk-3.8.1 regex-2024.5.15 textblob-0.18.0.post0 tqdm-4.66.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next day price change: 0.005098039215686301\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Sample news data\n",
    "news_data = pd.DataFrame({\n",
    "    'headline': ['Market up today', 'Stock prices fall', 'Economic growth slows'],\n",
    "    'date': ['2023-07-01', '2023-07-02', '2023-07-03']\n",
    "})\n",
    "\n",
    "# Compute sentiment scores\n",
    "news_data['sentiment'] = news_data['headline'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Ensure the 'date' column is in datetime format\n",
    "news_data['date'] = pd.to_datetime(news_data['date'])\n",
    "\n",
    "# Aggregate sentiment scores by date\n",
    "daily_sentiment = news_data.groupby('date')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Sample price data\n",
    "price_data = pd.DataFrame({\n",
    "    'date': ['2023-07-01', '2023-07-02', '2023-07-03'],\n",
    "    'price': [100, 102, 101]\n",
    "})\n",
    "\n",
    "# Ensure the 'date' column is in datetime format\n",
    "price_data['date'] = pd.to_datetime(price_data['date'])\n",
    "\n",
    "# Merge price data with daily sentiment scores\n",
    "data = pd.merge(price_data, daily_sentiment, on='date')\n",
    "\n",
    "# Calculate percentage change in price\n",
    "data['price_change'] = data['price'].pct_change().shift(-1)\n",
    "\n",
    "# Drop the last row with NaN value after shift operation\n",
    "data = data.dropna()\n",
    "\n",
    "# Use sentiment scores to predict price change\n",
    "X = data[['sentiment']]\n",
    "y = data['price_change']\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict the next day's price change based on the last sentiment score\n",
    "next_day_sentiment = X.iloc[[-1]]  # Use the last available sentiment score for prediction\n",
    "predicted_change = model.predict(next_day_sentiment)\n",
    "\n",
    "print(f'Predicted next day price change: {predicted_change[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Steps\n",
    "Compute Sentiment Scores: Use TextBlob to compute sentiment polarity scores for news headlines.\n",
    "Date Format Consistency: Ensure the date columns in both datasets are in datetime format.\n",
    "Aggregate Sentiment Scores: Use groupby and mean to aggregate sentiment scores by date.\n",
    "Merge Data: Combine the price data with the aggregated sentiment scores.\n",
    "Calculate Price Change: Compute the percentage change in price and shift it to align with the sentiment scores.\n",
    "Train and Predict: Train a linear regression model and predict the next day's price change based on the sentiment score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "The techniques and models provided cover various aspects of market risk management beyond just VaR. These include volatility forecasting, scenario analysis using Monte Carlo simulations, and leveraging sentiment analysis for market prediction. Deutsche Bank, like other financial institutions, would use a combination of these models tailored to their specific data, risk management strategies, and regulatory requirements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
